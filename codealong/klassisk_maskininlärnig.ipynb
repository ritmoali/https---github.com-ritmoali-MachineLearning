{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro till artificiel och neurala nätverk\n",
    "\n",
    "### Klassisk maskininlärning\n",
    "- regression, statistiska metoder\n",
    "\n",
    "### Neurala nätverk\n",
    "- 50-talet: basetat en i dag ntågot föräldrad syn op hjärnan.\n",
    "- Ändå  så abstract att det funkar ändå\n",
    "\n",
    "\n",
    "### MLP: Multileyered perception \n",
    "- 50-80 talet, teorin för hur man tränar djupa nätverk fanns inte. Dessutom beräkningsmässigt dyrt\n",
    "\n",
    "### SVM \n",
    "- expanderar featurerymden väldigt mycket, kollapsar dimensioner för att undvika overfit\n",
    "\n",
    "### NLP \n",
    "\n",
    "- Klassiska tekniker (innan 2017) räcker inte\n",
    "\n",
    "- #####GPT: generative pre_trained transformers\n",
    "- Transform: Encoder --> dolda lager --> Decoden/GPT\n",
    "- Emdedding: Omvanding ord till. Vi kallar dem då \"tokens\"\n",
    "\n",
    "### Attention\n",
    "- Du kanske inte är så dum ändå\n",
    " - skalär produkt mellan inböddade ord.\n",
    " Problem mellan syftningar, höger eller vänster asociation\n",
    "\n",
    " - Self_attention (masked self attention)\n",
    "\n",
    "titta endast åt ett håll\n",
    "\n",
    "DU kanske inte är så dum ändå\n",
    "\n",
    "### Optimeringsvillkor för oövervakad inlärning\n",
    "(pre-training)\n",
    "\n",
    "Vi lät alltså systsemet att lösa först.\n",
    "Sedan tränar vi övervakat \n",
    "<Sentence>| <answer>\n",
    "\n",
    "Då lär vi oss domänkunskap genom att förutsäga svaren\n",
    "(tex fakta om Mozart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataprocessing_Rithwan_Mohamed_Ali-jdCu2s_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
